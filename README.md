# ibaBeginingTask
Scala-based programm which creates db2 table

## Getting Started
To download project:
=======
Scala-based program which creates db2 table
## Data Load part
#### The aim of this part is to create  sql database with 20k rows base on DB2
#### You can create DB2 cloud using this link https://cloud.ibm.com/catalog/services/db2
#### The table colomns is:
1. product_id(Int) - autogenerated numeric
2. product_group(Int) - autogenerated numeric in 0..9 range
3. year(Int) - autogenerated numeric in 2015..2018 range
4-15.12 columns with monthly purchases amount - numeric in 0..100000 range 
## Getting Started
To download the project:
```
git clone https://github.com/KozlovKA/ibaBeginingTask
```
### Installing
To install all dependeies you need to print in terminal in `IbaTask` directory:
=======
To install all dependencies you need to print in the terminal in `IbaTask` directory:
```sh
sbt compile
```
### Running
<<<<<<< HEAD
If you want to run this proggram use next command in terminal:
```sh
sbt run
```
But there are two enviroental variables(bdUsername and dbPassword), so you should create it before start this program or you will get error.
## Built With

* [Scala](https://www.scala-lang.org/) - Scala is a strong statically typed general-purpose programming language which supports both object-oriented programming and functional programming.
=======
If you want to run this program use the next command in the terminal:
```sh
sbt run
```
But there are two environmental variables(bdUsername and dbPassword), so you should create it before starting this program or you will get an error.
## Data Transformation part
#### The aim of this part is to read data from cloud DB, to transform it into another view:
1. For each row calculate the total of monthly purchases
2. Save the year total as a new column year_purchases
3. Remove the columns with monthly amounts from the data frame
#### And to save the result to the Cloud Object Storage -> https://www.ibm.com/cloud/object-storage
In this part, we are starting to use spark so, if you have done all actions before you can use `spark-submit` to process it in the console, but you need to use some paramets to proceed it.
`dbUsername` -> your username to DB2 database

`dbPassword` -> your password to DB2 database

There we start working with STOCATOR lib, you should create a bucket on IBM cloud, when you create credentials for it don't forget to turn on Include HMAC Credential in Advanced Options

`access.key` -> your access_key_id in bucket credentials

`secret.key` -> your secret_access_key in bucket credentials

`endpoint` -> here you need to go to your endpoint link that is provided in bucket credentials and choose the same region one as your bucket region

Also you should use there --jars parametr with yours jar which has all inforamtion about your project classes and depenencies.You can create it by using:
```sh
sbt assembly
```

## Starting by using spark submit
#### So we got everythink that we need for spark-submit and for running our spark we need to use :  
```sh
spark-sumbit nameOfYourApplication-assembly-applicationVersion.jar
```
nameOfYourApplication-assembly-applicationVersion.jar - JAR file which was created by sby assembly, you can find it in projectName/targer/scala-version/

## Built With

* [Scala](https://www.scala-lang.org/) - Scala is a strong statically typed general-purpose programming language that supports both object-oriented programming and functional programming.
>>>>>>> master
* [Spark](https://spark.apache.org/) - Apache Spark is an open-source unified analytics engine for large-scale data processing.
* [MySql](https://www.mysql.com/) - SQL is a domain-specific language used in programming and designed for managing data held in a relational database management system, or for stream processing in a relational data stream management system

## Authors

* **Kirill Kozlov** - 
[LinkedIn](https://www.linkedin.com/in/kozlovka/) | 
[GitHub](https://github.com/KozlovKA)
